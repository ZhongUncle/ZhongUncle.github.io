<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv='content-language' content='zh-CN'>
        <title>在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="/assets/css/headerstyle.css" />
        <link rel="stylesheet" type="text/css" href="/assets/css/blogstyle.css" />
        <link rel="stylesheet" type="text/css" href="/assets/css/style.css" />
        <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="测试了一下目前笔记本和 Mac mini 运行使用 Pytorch 构建的最简单的单层 NN （带有反向传播）的 10 次迭代，这样以后购买设备就知道需要注重哪些参数了，可惜没有。" />
<meta property="og:description" content="测试了一下目前笔记本和 Mac mini 运行使用 Pytorch 构建的最简单的单层 NN （带有反向传播）的 10 次迭代，这样以后购买设备就知道需要注重哪些参数了，可惜没有。" />
<link rel="canonical" href="http://localhost:4000/blogs/50809ae558e6bc2de8441aaad7a19d39.html" />
<meta property="og:url" content="http://localhost:4000/blogs/50809ae558e6bc2de8441aaad7a19d39.html" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-17T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-02-17T00:00:00+08:00","datePublished":"2023-02-17T00:00:00+08:00","description":"测试了一下目前笔记本和 Mac mini 运行使用 Pytorch 构建的最简单的单层 NN （带有反向传播）的 10 次迭代，这样以后购买设备就知道需要注重哪些参数了，可惜没有。","headline":"在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blogs/50809ae558e6bc2de8441aaad7a19d39.html"},"url":"http://localhost:4000/blogs/50809ae558e6bc2de8441aaad7a19d39.html"}</script>
<!-- End Jekyll SEO tag -->

    </head>
    <body>
        <div class="stackedit__html">
            <!-- 这个文件里是用来生成导航栏的 -->
<div class="header">
    
        <a href="/index.html" class="headerItem">
            主页
        </a>
    
        <a href="/swiftui.html" class="headerItem">
            SwiftUI
        </a>
    
        <a href="/unix.html" class="headerItem">
            UNIX
        </a>
    
        <a href="/plan9.html" class="headerItem">
            Plan 9
        </a>
    
        <a href="/web.html" class="headerItem">
            Web
        </a>
    
        <a href="/research.html" class="headerItem">
            Research
        </a>
    
        <a href="/book.html" class="headerItem">
            Book
        </a>
    
        <a href="/non-tech.html" class="headerItem">
            Non-Tech
        </a>
    
</div>
            <h1>在笔记本和 Mac mini 2018 上 Pytorch 实现的简单 NN 性能测试</h1>
            <div class="bloginfo">
                <p class="info">2023-02-17 ｜ <a href="/research.html"> Research</a> ｜ 908 字</p>
            </div>
            <!-- excerpt-start -->
<p>测试了一下目前笔记本和 Mac mini 运行使用 Pytorch 构建的最简单的单层 NN （带有反向传播）的 10 次迭代，这样以后购买设备就知道需要注重哪些参数了，可惜没有。</p>

<p>首先是各个设备的性能：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Dell Inspiron 7490</th>
      <th>Mac mini 2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CPU</td>
      <td>i7 10510U 4C8T 2.30-4.90GHz</td>
      <td>i5 8500B 6C6T 3.00-4.10GHz</td>
    </tr>
    <tr>
      <td>Cache</td>
      <td>8 MB</td>
      <td>9MB</td>
    </tr>
    <tr>
      <td>内存</td>
      <td>16GB DDR3 2133MHz</td>
      <td>32GB DDR4 2666MHz</td>
    </tr>
    <tr>
      <td>最优 GPU</td>
      <td>MX250 4SM 384 CUDA Core 64-bit 2GB GDDR5</td>
      <td>Intel® UHD Graphics 630 1.10 GHz</td>
    </tr>
  </tbody>
</table>

<p>下面结果取最好/中间值，唯一可惜的是 iMac 5K 卖早了，不然可以测一下 mps 加速的结果。因为 Python 的 mps 加速只在苹果芯片和搭载了 AMD 显卡的设备上支持。</p>

<table>
  <thead>
    <tr>
      <th>Dell Inspiron 7490 CPU</th>
      <th>Dell Inspiron 7490 GPU</th>
      <th>Mac mini 2018</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>123.15s</td>
      <td>107.79s</td>
      <td>87.94s</td>
    </tr>
  </tbody>
</table>

<p>最神奇的是 8500B 居然比 MX250 CUDA 加速之后的时间还短，当然这里很大概率是系统的问题，毕竟 Windows 性能表现确实不太行。</p>

<p>此外，显存带宽也真的很重要（虽然大小也重要），MX250 带宽太小，毕竟就 64-bit 的 GDDR5（也就是48GB/s），加迭代和降低学习速度等操作之后，CUDA 计算速率都上不去。不过一般消费级显卡的显存带宽也够用，只是 MX250 定位是轻薄本用。
这让我想到了我之前看别人做的测试 <a href="https://sebastianraschka.com/blog/2022/pytorch-m1-gpu.html">Running PyTorch on the M1 GPU</a>，其中有个数据是 RTX 3080 Laptop 要比 RTX 2080Ti 稍慢一些：</p>

<p><img alt="别人测试的图" src="/assets/images/vgg-benchmark-training.png" style="box-shadow: 0px 0px 0px 0px" /></p>

<p>上图中各显卡参数和成绩如下：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>GTX 1080Ti</th>
      <th>Titan V</th>
      <th>RTX 2080Ti</th>
      <th>RTX 3060 Laptop</th>
      <th>RTX 3080 Laptop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cuda Cores</td>
      <td>3584</td>
      <td>5120</td>
      <td>4352</td>
      <td>3840</td>
      <td>6144</td>
    </tr>
    <tr>
      <td>显存接口</td>
      <td>352-bit</td>
      <td>3072-bit</td>
      <td>352-bit</td>
      <td>192-bit</td>
      <td>256-bit</td>
    </tr>
    <tr>
      <td>显存速率（Gbps）</td>
      <td>11</td>
      <td>1.7</td>
      <td>14</td>
      <td>14</td>
      <td>14</td>
    </tr>
    <tr>
      <td>显存带宽（GB/s）</td>
      <td>484</td>
      <td>652.8</td>
      <td>616</td>
      <td>336</td>
      <td>448</td>
    </tr>
    <tr>
      <td>分钟/epoch</td>
      <td>7.65</td>
      <td>5.03</td>
      <td>5.75</td>
      <td>14.53</td>
      <td>6.66</td>
    </tr>
  </tbody>
</table>

<p>因为显存大小都为 10 GiB 左右，就不列出了，而且这里也没有超过显存大小。</p>

<p><img src="/assets/images/bc6ba17af8cdca3cccbe0a980fda184b.png" style="box-shadow: 0px 0px 0px 0px" /></p>

<p>下图中“比例”部分关于“分钟/epoch”使用标准性能计算公式（如果你想质疑这个公式麻烦写论文去发 JACM）:</p>

<p><img alt="标准性能计算公式" src="/assets/images/t27e187te8712.png" style="box-shadow: 0px 0px 0px 0px" /></p>

<p>这样看可能不是很清楚，所以只保留“Cuda Cores”、“显存带宽”和“性能”来一张图，因为其他部分也都是与“显存带宽”相关的，所以就忽略掉：</p>

<p><img alt="“Cuda Cores”、“显存带宽”、“性能”和运行结果的曲线图" src="/assets/images/2485e6c0d1e87391fac8337c7079b2e0.png" style="box-shadow: 0px 0px 0px 0px" /></p>

<p>这样可以很清楚的看到，训练模型的性能和显存带宽、Cuda 数量的关系非常大。</p>

<p>当然，这里的显存带宽和性能是直接相关的，而 Cuda 数量则不一定。因为上面除了 GTX 1080 Ti 之外，都含有专门用来计算张量的 Tensor Core，所以要看具体实现。现在看 Tensor Core 的性能比较多，不过一般 Tensor Core 数量与 Cuda Core 数量挂钩。</p>

<p>当然如果你能直接找到相关 GPU 的浮点性能就更好了，这个更直接一些。研究这些是因为消费级 GPU 的浮点性能不是很好找。</p>

        </div>
    </body>
</html>