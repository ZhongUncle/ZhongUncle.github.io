<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv='content-language' content='en'>
        <title>Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2)</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="/assets/css/headerstyle.css" />
        <link rel="stylesheet" type="text/css" href="/assets/css/blogstyle.css" />
        <link rel="stylesheet" type="text/css" href="/assets/css/style.css" />
        <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2) | ZhongUncle’s Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This blog shares some reviews and tests of Raspberry Pi 4B. ZhongUncle compares it with Mac mini 2018 i5 in many aspects." />
<meta property="og:description" content="This blog shares some reviews and tests of Raspberry Pi 4B. ZhongUncle compares it with Mac mini 2018 i5 in many aspects." />
<link rel="canonical" href="https://zhonguncle.github.io/blogs/31b3837229d1c680ac512eb13a35047d.html" />
<meta property="og:url" content="https://zhonguncle.github.io/blogs/31b3837229d1c680ac512eb13a35047d.html" />
<meta property="og:site_name" content="ZhongUncle’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-05T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-11-05T00:00:00+08:00","datePublished":"2023-11-05T00:00:00+08:00","description":"This blog shares some reviews and tests of Raspberry Pi 4B. ZhongUncle compares it with Mac mini 2018 i5 in many aspects.","headline":"Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2)","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhonguncle.github.io/blogs/31b3837229d1c680ac512eb13a35047d.html"},"url":"https://zhonguncle.github.io/blogs/31b3837229d1c680ac512eb13a35047d.html"}</script>
<!-- End Jekyll SEO tag -->

        
        <!-- Microsoft Clarity -->
        <script type="text/javascript">
            (function(c,l,a,r,i,t,y){
                c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
                t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
                y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
            })(window, document, "clarity", "script", "ix8xlal10a");
        </script>

        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-SS87H0FDV7"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-SS87H0FDV7');
        </script>

        
    </head>
    <body>
        <div class="stackedit__html">
            <!-- 这个文件里是用来生成导航栏的 -->
<div class="header">
    
        <a href="/index.html" class="headerItem">
            主页
        </a>
    
        <a href="/swift.html" class="headerItem">
            Swift
        </a>
    
        <a href="/unix.html" class="headerItem">
            UNIX
        </a>
    
        <a href="/c.html" class="headerItem">
            C
        </a>
    
        <a href="/assembly.html" class="headerItem">
            Assembly
        </a>
    
        <a href="/go.html" class="headerItem">
            Go
        </a>
    
        <a href="/plan9.html" class="headerItem">
            Plan 9
        </a>
    
        <a href="/web.html" class="headerItem">
            Web
        </a>
    
        <a href="/mcu.html" class="headerItem">
            MCU
        </a>
    
        <a href="/research.html" class="headerItem">
            Research
        </a>
    
        <a href="/non-tech.html" class="headerItem">
            Non-Tech
        </a>
    
</div>
            <h1>Performance Record of Raspberry Pi 4B (CPU, Disk, FFMPEG, CV, llama2)</h1>
            <div class="bloginfo">
                <p class="info">2023-11-05 ｜ <a href="/research.html"> Research</a> ｜ #Words: 1680 </p>
            </div>
            <p>This blog is used to record some reviews of Raspberry Pi 4B.</p>

<h2 id="temperature">Temperature</h2>
<p>Fans and Large Fans are:</p>

<p><img src="/assets/images/1d1332465d7d4cc7a107c84951b0649a.jpeg" alt="Please add image description" /></p>

<p>Why use a large fan?</p>

<p>Because a small fan on the case can cause noise from airflow through the case grid, which is not pleasant but not very loud. A large fan does not have this problem and it also uses the Raspberry Pi’s USB port for power supply.Additionally, because the Raspberry Pi is located next to the large hard drive, it can also cool the system.</p>

<h3 id="idle">Idle</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Temperature(℃)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>No fin + No fan</td>
      <td>41.3</td>
    </tr>
    <tr>
      <td>Fin</td>
      <td>38.9</td>
    </tr>
    <tr>
      <td>Fin + Fan</td>
      <td>36.5</td>
    </tr>
    <tr>
      <td>Fin + Large fan</td>
      <td>29.7</td>
    </tr>
  </tbody>
</table>

<h3 id="full-load">Full Load</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Temperature(℃)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Fin</td>
      <td>69.6</td>
    </tr>
    <tr>
      <td>Fin + Fan</td>
      <td>56.9</td>
    </tr>
    <tr>
      <td>Fin + Large fan</td>
      <td>50.6</td>
    </tr>
  </tbody>
</table>

<h2 id="io-speed">I/O speed</h2>
<p>Raspberry Pi 4B Micro SD has a write speed of 45 MB/s, but occasionally it can run up to 100 MB/s for reading, which is mostly similar to the read speed (Jeff tested that Raspberry Pi 5 can run full 100MB/s).</p>

<h2 id="cpu-performance">CPU performance</h2>
<p>Below I write programs using Clang and ISPC (parallel computing) to test some performance of the CPU. Considering the impact of write speed of Micro SD Card, only test non-stored programs here.</p>

<h3 id="4096x4096-float64-matrix-calculation">4096x4096 Float64 matrix calculation</h3>
<p>If divided 4 blocks for parallel computation:</p>

<table>
  <thead>
    <tr>
      <th>Device</th>
      <th>Serial</th>
      <th>Parallel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi 4B (4C4T)</td>
      <td>66.12s</td>
      <td>51.72s</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 (6C6T)</td>
      <td>17.76s</td>
      <td>6.08s</td>
    </tr>
  </tbody>
</table>

<p>The process occupies approximately 192.8 MB memory. It can be seen that the improvement brought by the use of parallel computing and segmentation tasks, but Raspberry Pi 4B is not nearly four times as expected.</p>

<p>I think the blocks processed each time exceed the size of each core’s 32kB data L1 cache. Using a smaller block maybe better? In theory, it is the fastest on 16x16, which is divided into 256 blocks, because the maximum matrix stored in 32Kb is about 22x22.</p>

<p>Each of the tests uses the same matrix:</p>

<table>
  <thead>
    <tr>
      <th>Blocks (each block size)</th>
      <th>Test 1</th>
      <th>Test 2</th>
      <th>Test 3</th>
      <th>Test 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>4 (1024x1024)</td>
      <td>40s</td>
      <td>39s</td>
      <td>47s</td>
      <td>41s</td>
    </tr>
    <tr>
      <td>8 (512x512)</td>
      <td>56s</td>
      <td>47s</td>
      <td>55s</td>
      <td>48s</td>
    </tr>
    <tr>
      <td>16 (256x256)</td>
      <td>37s</td>
      <td>39s</td>
      <td>40s</td>
      <td>46s</td>
    </tr>
    <tr>
      <td>32 (128x128)</td>
      <td>38s</td>
      <td>49s</td>
      <td>48s</td>
      <td>50s</td>
    </tr>
    <tr>
      <td>64 (64x64)</td>
      <td>45s</td>
      <td>49s</td>
      <td>45s</td>
      <td>42s</td>
    </tr>
    <tr>
      <td>128 (32x32)</td>
      <td>41s</td>
      <td>37s</td>
      <td>43s</td>
      <td>40s</td>
    </tr>
    <tr>
      <td>256 (16x16)</td>
      <td>38s</td>
      <td>38s</td>
      <td>43s</td>
      <td>37s</td>
    </tr>
  </tbody>
</table>

<p>16x16 maybe not fastest every time, but you can see 16x16 is definitely the first tier. We choose <code class="language-plaintext highlighter-rouge">40s</code> as result, it reaches 1.653 times  of serial, which is close to twice times.</p>

<h3 id="optimized-matrix-multiplication-measuring-floating-point-performance">Optimized matrix multiplication (measuring floating-point performance)</h3>
<p>Use optimized matrices and algorithms and task. This test can achieve 70% to 90% of peak floating-point performance, but the actual situation still depends on the operating status, system, and other configurations.</p>

<table>
  <thead>
    <tr>
      <th>Device</th>
      <th>Floating Point Performance (GFLOPS)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi 4B</td>
      <td>11.91</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5</td>
      <td>200.03</td>
    </tr>
  </tbody>
</table>

<p>The comparison group here achieved 70% of the theoretical performance (200/288), and the Raspberry Pi was much higher than the floating-point value obtained from the previous test.</p>

<h3 id="sort">Sort</h3>

<table>
  <thead>
    <tr>
      <th>Devices</th>
      <th>Parallel Computing + Tasks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi 4B (4C4T)</td>
      <td>2.45x</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 (6C6T)</td>
      <td>5.86x</td>
    </tr>
  </tbody>
</table>

<p>The process occupies approximately 192.8 MB of memory. It also doesn’t achieve the 4 times expected result, also is about 2 times.</p>

<h3 id="mandelbrot">Mandelbrot</h3>

<table>
  <thead>
    <tr>
      <th>Devices</th>
      <th>Parallel Computing + Tasks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi 4B (4C4T)</td>
      <td>8.58x</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 (6C6T)</td>
      <td>44.03x</td>
    </tr>
    <tr>
      <td>(reference) Intel E5-2690 v4 x2 (28C58T)</td>
      <td>130.18x</td>
    </tr>
  </tbody>
</table>

<p>You can see the improvement of each device has reached twice the number of threads.</p>

<h3 id="some-my-opinions">Some my opinions</h3>
<p>These test proved that the low cache of BCM2711 (32kB of data + 48kB of instruction L1 cache  per core and totally 1MB L2 cache) results the required data for computation is slightly larger, the parallel performance will not reach the expected, and cannot fully utilize the performance of all cores.</p>

<p>Of course, I suspect this is also related to the lack of optimization and improvement of the new system (Bookworm). Let’s see if it will be better in the future.</p>

<h2 id="ffmpeg">FFMPEG</h2>
<p>Sometimes need to convert formats, transcoding and fixing issues with some videos. I prefer to use ffmpeg.</p>

<p>The unit ‘x’ in the test results meaning the ratio of the frames processed per second and the average frames in the video, like’123x’. For example, if the video is 24 Hz, processe 48 frames per second, it will display ‘2x’; If only 12 frames per second, ‘0.5x’ will be displayed.</p>

<p>Test Video: 950MB FLV Tiktok live record with 500K bitrate.</p>

<h3 id="convert-video-format">Convert Video Format</h3>
<p>The fastest way to convert formats is to directly copy the stream, as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ffmpeg -i input.mkv -c copy out.mp4
</code></pre></div></div>

<p>This method does not modify any audio/video, encoder or bitrate, because it directly captures the stream into a new format (notice the selection of subtitles and audio tracks).</p>

<p>The results and comparison of Raspberry Pi 4 are as follows:</p>

<table>
  <thead>
    <tr>
      <th>Device</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi+Micro SD (45MB/s)</td>
      <td>35x</td>
    </tr>
    <tr>
      <td>Raspberry Pi+USB NVMe SSD (approximately 350MB/s)</td>
      <td>617x</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 (read 2400 write 1200)</td>
      <td>2410x</td>
    </tr>
  </tbody>
</table>

<p>As the speed of the hard drive increases, the speed of transcode increases.</p>

<blockquote>
  <p>Notice the speed of the USB SSD mentioned above is limited by the solid-state drive itself, as it uses BG4 and does not have memory as a buffer. Due to the addition of single flash memory particles and TLC NAND, it is not only can’t achieve expected IOPS performance when using USB external connections (internal connections use system memory as a buffer), but also inferior to other SSDs with memory buffering or multiple NAND.</p>
</blockquote>

<blockquote>
  <p>IOPS is the number of operations of read and write per second, which affects the system’s response speed.</p>
</blockquote>

<h3 id="transcode">Transcode</h3>
<p>The simplest commands in daily life:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ffmpeg -i in.flv out.mp4
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>Device</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi + Micro SD (45MB/s)</td>
      <td>0.23x</td>
    </tr>
    <tr>
      <td>Raspberry Pi + USB NVMe SSD (approximately 350MB/s)</td>
      <td>0.452x</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 (read 2400 write 1200)</td>
      <td>2.7x</td>
    </tr>
  </tbody>
</table>

<h3 id="hardware-accelerated-transcoding">Hardware accelerated transcoding</h3>

<p>To use hardware accelerated transcoding on raspberry pi, the command like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ffmpeg -i in.flv -c:v h264_V4l2m2m -b:v 1500k out.mp4
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">1500k</code> is not the bitrate of the video. It is the bitrate of the automatic transcoding in the previous section. I will use it to compare. I also tested other bitrates and the speed is similar like below:</p>

<table>
  <thead>
    <tr>
      <th>Device</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raspberry Pi + Micro SD (45MB/s)</td>
      <td>2.1x</td>
    </tr>
    <tr>
      <td>Raspberry Pi + USB NVMe SSD (approximately 350MB/s)</td>
      <td>2.36x</td>
    </tr>
    <tr>
      <td>(reference) Mac mini 2018 i5 UHD 630 (read 2400 write 1200)</td>
      <td>4.36x</td>
    </tr>
  </tbody>
</table>

<p>Raspberry Pi 4B has increased its speed by 6-10 times after using hardware acceleration. However, the ‘h264’_V4l2m2m` occupies CPU usage. And if you are running other programs, the performance will decrease slightly.</p>

<h2 id="machine-learning">Machine Learning</h2>
<p>The speed of image recognition and large language model was tested.</p>

<h3 id="image-identification">Image Identification</h3>

<p>30 frames 224x224 size from the camera, using mobilenet_v2 for recognition, the speed is about 36 fps.
<img src="/assets/images/4c8e4b5ab7d9481ca4b2b9c3b3a332a7.png" alt="30 frames 224x224 size from the camera" /></p>

<h3 id="large-language-model">Large language model</h3>
<p>Use a small large language model <a href="https://github.com/karpathy/llama2.c">karpathy/llama2.c</a> for testing. Models with different size parameters have different speeds:</p>

<table>
  <thead>
    <tr>
      <th>Model parameter size</th>
      <th>Speed (tokens/s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>15M</td>
      <td>30.1</td>
    </tr>
    <tr>
      <td>42M</td>
      <td>11.2</td>
    </tr>
    <tr>
      <td>110M</td>
      <td>4.3</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/images/d0959cf3e7164019b3676f9c04341eed.png" alt="llama speed above" /></p>

<h2 id="why-i-still-buy-raspberry-pi-4">Why I still buy Raspberry Pi 4</h2>
<p>Why although Raspberry Pi 5 has been released, I still bought Raspberry Pi 4B, considering the following points:</p>
<ol>
  <li>The power consumption of Raspberry Pi 5 has increased by 10 Watts, and doesn’t need to buy a special chargers (4B can many current phone chargers use directly, even can use the USB charger port on monitor). It also needs a heat sink and fan (Jeff’s test results have proven this).</li>
  <li>Although the performance of Raspberry Pi 5 has increased by 2-3 times, the actual price has also increased much. You may say that the official price has only increase $5. However, it needs to be considered that there are not many 5V5A chargers currently used, and a heat sink must be used. So based on the price from the official designated merchant, 4GB is ¥550(about $80), plus the official charger and heat sink, that’s 700 yuan (about $100), and at this price, I can buy an N100 miniPC with twice the performance and M.2 + SATA interface.</li>
  <li>I need to use it to debug Raspberry Pi Pico, which happens to have a debugging interface on Raspberry Pi, and it doesn’t require any performance.</li>
  <li>Raspberry Pi 5 may have some issues because it just comes out. I want to use it for a long time. Now Raspberry Pi 4B has sold at least 3 million, the possibility of serious problems is impossible.</li>
  <li>To be honest, last time I bought a Raspberry Pi 4B, I didn’t use it’s performance fully. And Raspberry Pi 5 has not publicly stated that it does not support OpenCL, and 4B cannot be used.</li>
  <li>The most crucial thing is that the Raspberry Pi 5 has not yet started selling in China, and the Double Eleven subsidy Raspberry Pi 4B 4GB bare board only costs 330 yuan($48).</li>
</ol>

<p>I hope these will help someone in need~</p>

        </div>
        <!-- comment by utterances -->
        <script src="https://utteranc.es/client.js"
        repo="ZhongUncle/zhonguncle.github.io"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
        </script>
        <!-- <div class="footer__html">
            <p>
                You can find me in: 
                <a href="https://blog.csdn.net/qq_33919450">CSDN</a>
                <a href="https://github.com/ZhongUncle">GitHub</a>
            </p>
        </div> -->
    </body>
</html>